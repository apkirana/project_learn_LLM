{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import textwrap\n",
    "import requests  # For making API calls\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load API Key (from .env file or environment variables)---\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # Recommend using a .env file\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"API key for OPEN AI is not set.  \"\n",
    "                     \"Set it in a .env file or as an environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Simulated User Input (Data Loading) ---\n",
    "def simulate_satellite_data(num_points=100):\n",
    "    #Same function from previous answer)\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'latitude': np.random.uniform(30, 50, num_points),\n",
    "        'longitude': np.random.uniform(-125, -70, num_points),\n",
    "        'ndvi': np.random.rand(num_points),\n",
    "    }\n",
    "    data['ndvi'] += 0.2 * np.sin(data['latitude'] * np.pi / 180)\n",
    "    data['ndvi'] = np.clip(data['ndvi'], 0, 1)\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODIFIED: Function to call the OpenAI API (Corrected for v1.0.0+) ---\n",
    "def call_openai(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"Calls the OpenAI API (Chat Completions - Corrected for v1.0.0+).\"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI() # Use the client for openai>=1.0.0\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_tokens=350,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    except openai.OpenAIError as e: #Corrected exception class\n",
    "        print(f\"OpenAI API error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "  Geospatial Analysis System (Simulated)\n",
      "----------------------------------------\n",
      "\n",
      "User Query: What is the size of the vegetation area?\n",
      "\n",
      "Simulated Input Data (First 5 Rows):\n",
      "    latitude   longitude      ndvi\n",
      "0  37.490802 -123.271395  0.763758\n",
      "1  49.014286  -89.997427  0.235115\n",
      "2  44.639879 -107.710421  0.302158\n",
      "3  41.973170  -97.028612  1.000000\n",
      "4  33.120373  -75.083844  0.715709\n"
     ]
    }
   ],
   "source": [
    "# --- 2. LLM Agent (Task Understanding and Code Generation - Simulated) ---\n",
    "# Simulate LLM agent data retrieval\n",
    "df = simulate_satellite_data()\n",
    "print(\"-\" * 40)\n",
    "print(\"  Geospatial Analysis System (Simulated)\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\\nUser Query: What is the size of the vegetation area?\")\n",
    "print(\"\\nSimulated Input Data (First 5 Rows):\")\n",
    "print(df.head())\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model.fit(df[['latitude', 'longitude']], df['ndvi'])\n",
    "\n",
    "results = permutation_importance(\n",
    "    model, df[['latitude', 'longitude']], df['ndvi'],\n",
    "    n_repeats=10, random_state=42\n",
    ")\n",
    "importance = results.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt (Slightly adjusted) ---\n",
    "prompt = f\"\"\"\n",
    "You are a geospatial analysis assistant. A user has asked:\n",
    "\"What is the size of the vegetation area?\"\n",
    "\n",
    "We've used a SIMPLIFIED model with latitude, longitude, and simulated NDVI\n",
    "to estimate vegetation. A real analysis would use satellite imagery.  We\n",
    "calculated feature importances:\n",
    "\n",
    "Latitude Importance: {importance[0]:.4f}\n",
    "Longitude Importance: {importance[1]:.4f}\n",
    "\n",
    "Explain these results in simple terms. What does feature importance mean in\n",
    "this context?  Based on these importances, is location strongly or weakly\n",
    "related to vegetation? Acknowledge the simplification. DO NOT invent a\n",
    "specific area size. Explain *why* latitude/longitude MIGHT influence\n",
    "vegetation (climate, sunlight, etc.).  Be concise and factual.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 12\u001b[0m, in \u001b[0;36mcall_openai\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m350\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust as needed\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of completions to generate\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Optional: Sequences where the API will stop generating\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust for creativity (0.0 to 1.0)\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Documents/GitHub/project_learn_TalkToEBM/.venv/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Call the OpenAI API ---\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m explanation_raw \u001b[38;5;241m=\u001b[39m \u001b[43mcall_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Or \"gpt-4\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explanation_raw:\n\u001b[1;32m      5\u001b[0m     wrapper \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mTextWrapper(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "Cell \u001b[0;32mIn[87], line 25\u001b[0m, in \u001b[0;36mcall_openai\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m     12\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     13\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     14\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,  \u001b[38;5;66;03m# Adjust for creativity (0.0 to 1.0)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[38;5;241m.\u001b[39mOpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'error'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Call the OpenAI API ---\n",
    "explanation_raw = call_openai(prompt, model=\"gpt-4o-mini\")  # Or \"gpt-4\"\n",
    "\n",
    "if explanation_raw:\n",
    "    wrapper = textwrap.TextWrapper(width=80)\n",
    "    explanation_wrapped = wrapper.fill(text=explanation_raw)\n",
    "\n",
    "    print(\"\\n--- LLM Agent Response ---\")\n",
    "    print(\"\\nPrompt:\\n\")\n",
    "    print(wrapper.fill(text=prompt))\n",
    "\n",
    "    print(\"\\nExplanation:\\n\")\n",
    "    print(explanation_wrapped)\n",
    "else:\n",
    "    print(\"\\n--- LLM Agent Response ---\")\n",
    "    print(\"\\nError: Could not retrieve explanation from OpenAI API.\")\n",
    "\n",
    "print(\"\\n--- xAI Geospatial Results ---\")\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(f\"  Latitude:  {importance[0]:.4f}\")\n",
    "print(f\"  Longitude: {importance[1]:.4f}\")\n",
    "print(\"\\n--- End of Simulation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
